{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis by Structural Groups (RQ1 & RQ2)\n",
    "\n",
    "**Structure groups**: Centralized (sequential_fanout, parallel_fanout), Structured (chain_with_branching, hierarchical_tree), Probabilistic (probabilistic_tree), Dense (complex_mesh).\n",
    "\n",
    "**Steps:**\n",
    "1. **Normality** — Shapiro–Wilk by topology; short summary + LaTeX paragraph (non-parametric justification).\n",
    "2. **RQ1 Energy** — Kruskal–Wallis on **Energy (J)** only; structural contrasts (Dense vs Others, Centralized vs Structured, Seq vs Par, Prob vs Det). Energy per request / per success / per RPS are computed in the notebook but excluded from the paper output per discourse.\n",
    "3. **Size interaction** — Topology × Size for energy and throughput (rank-based two-way).\n",
    "4. **RQ2 Performance–Energy** — Spearman correlations per topology (throughput–energy, latency–energy, failure–energy).\n",
    "5. **Efficiency** — energy_per_rps is computed but not included in the merged paper output.\n",
    "6. **Output**: Only `tables/table3_4_5_statistics.tex` (single file to include in the paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T21:50:34.703231Z",
     "iopub.status.busy": "2026-02-20T21:50:34.702868Z",
     "iopub.status.idle": "2026-02-20T21:50:36.341252Z",
     "shell.execute_reply": "2026-02-20T21:50:36.338873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN_TABLE_PATH: /home/irena/Documents/Research Project/topology-scale-mubench-replication/5_results_data/run_table.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "cwd = Path('.').resolve()\n",
    "# Find repo root by walking up to directory containing 5_results_data/run_table.csv\n",
    "_run_table = Path('5_results_data') / 'run_table.csv'\n",
    "_search = cwd\n",
    "RUN_TABLE_PATH = None\n",
    "for _ in range(6):\n",
    "    candidate = _search / _run_table\n",
    "    if candidate.exists():\n",
    "        RUN_TABLE_PATH = candidate\n",
    "        break\n",
    "    _search = _search.parent\n",
    "if RUN_TABLE_PATH is None:\n",
    "    RUN_TABLE_PATH = cwd / _run_table\n",
    "# Outputs go to 5_results_analysis/tables (one level up when running from notebooks/)\n",
    "TABLES_DIR = (cwd.parent / 'tables') if cwd.name == 'notebooks' else (cwd / 'tables')\n",
    "TABLES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TOPOLOGY_TO_STRUCTURE = {\n",
    "    'sequential_fanout': 'centralized',\n",
    "    'parallel_fanout': 'centralized',\n",
    "    'chain_with_branching': 'structured',\n",
    "    'hierarchical_tree': 'structured',\n",
    "    'probabilistic_tree': 'probabilistic',\n",
    "    'complex_mesh': 'dense',\n",
    "}\n",
    "CORE_METRICS = ['throughput_rps', 'avg_latency_s', 'energy_kj', 'cpu_usage_avg']\n",
    "OPTIONAL_METRICS = ['failure_rate', 'p95_latency_s']\n",
    "METRIC_LABELS = {\n",
    "    'throughput_rps': 'Throughput (RPS)',\n",
    "    'avg_latency_s': 'Avg. response time (s)',\n",
    "    'energy_kj': 'Energy (kJ)',\n",
    "    'cpu_usage_avg': 'CPU utilization',\n",
    "    'failure_rate': 'Failure rate',\n",
    "    'p95_latency_s': 'P95 latency (s)',\n",
    "}\n",
    "ALPHA = 0.05\n",
    "print(\"RUN_TABLE_PATH:\", RUN_TABLE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T21:50:36.409758Z",
     "iopub.status.busy": "2026-02-20T21:50:36.408547Z",
     "iopub.status.idle": "2026-02-20T21:50:36.450739Z",
     "shell.execute_reply": "2026-02-20T21:50:36.447285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 180 runs. Structure groups:\n",
      "{'centralized': 60, 'structured': 60, 'probabilistic': 30, 'dense': 30}\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(RUN_TABLE_PATH)\n",
    "df = df[df['__done'] == 'DONE'].copy()\n",
    "df['structure_group'] = df['topology'].map(TOPOLOGY_TO_STRUCTURE)\n",
    "if 'failure_rate' in df.columns and df['failure_rate'].max() <= 1.5:\n",
    "    df['failure_rate'] = df['failure_rate'] * 100\n",
    "if 'cpu_usage_avg' in df.columns and df['cpu_usage_avg'].max() <= 1.5:\n",
    "    df['cpu_usage_avg'] = df['cpu_usage_avg'] * 100\n",
    "# Units for paper: energy in kJ, latency in s\n",
    "df['energy_kj'] = df['energy'] / 1000\n",
    "df['avg_latency_s'] = df['avg_latency_ms'] / 1000\n",
    "df['p95_latency_s'] = df['p95_latency_ms'] / 1000\n",
    "# Derived energy metrics (for RQ1 and efficiency; efficiency excluded from paper output)\n",
    "df['energy_per_request'] = df['energy'] / df['request_count'].replace(0, np.nan)\n",
    "safe_success = (df['request_count'] * (1 - df['failure_rate'] / 100)).replace(0, np.nan)\n",
    "df['energy_per_success'] = df['energy'] / safe_success\n",
    "df['energy_per_rps'] = df['energy'] / df['throughput_rps'].replace(0, np.nan)\n",
    "\n",
    "metrics = CORE_METRICS + [m for m in OPTIONAL_METRICS if m in df.columns]\n",
    "print(f\"Loaded {len(df)} runs. Structure groups:\\n{df['structure_group'].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Normality (Shapiro–Wilk) by topology\n",
    "\n",
    "Per (metric, topology). Small summary table + short LaTeX paragraph: normality violated → non-parametric tests used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T21:50:36.455554Z",
     "iopub.status.busy": "2026-02-20T21:50:36.455352Z",
     "iopub.status.idle": "2026-02-20T21:50:36.512932Z",
     "shell.execute_reply": "2026-02-20T21:50:36.510931Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normality by topology (sample):\n",
      "            metric              topology       p_value\n",
      "0   throughput_rps  chain_with_branching  7.243727e-05\n",
      "1   throughput_rps          complex_mesh  1.271340e-06\n",
      "2   throughput_rps     hierarchical_tree  6.005541e-05\n",
      "3   throughput_rps       parallel_fanout  1.546559e-04\n",
      "4   throughput_rps    probabilistic_tree  9.380843e-05\n",
      "5   throughput_rps     sequential_fanout  4.748467e-05\n",
      "6    avg_latency_s  chain_with_branching  4.595411e-06\n",
      "7    avg_latency_s          complex_mesh  9.001686e-07\n",
      "8    avg_latency_s     hierarchical_tree  3.542815e-06\n",
      "9    avg_latency_s       parallel_fanout  1.232518e-05\n",
      "10   avg_latency_s    probabilistic_tree  1.398755e-04\n",
      "11   avg_latency_s     sequential_fanout  2.522946e-06\n",
      "\n",
      "Majority p < 0.05 (non-normal) per metric: {'avg_latency_s': True, 'cpu_usage_avg': True, 'energy_kj': True, 'failure_rate': True, 'p95_latency_s': True, 'throughput_rps': True}\n"
     ]
    }
   ],
   "source": [
    "NORM_METRICS = ['throughput_rps', 'avg_latency_s', 'p95_latency_s', 'energy_kj', 'failure_rate', 'cpu_usage_avg']\n",
    "norm_rows = []\n",
    "for col in NORM_METRICS:\n",
    "    if col not in df.columns:\n",
    "        continue\n",
    "    for topo, grp in df.groupby('topology'):\n",
    "        vals = grp[col].dropna()\n",
    "        if len(vals) < 3:\n",
    "            continue\n",
    "        _, p = stats.shapiro(vals)\n",
    "        norm_rows.append({'metric': col, 'topology': topo, 'p_value': p})\n",
    "norm_df = pd.DataFrame(norm_rows)\n",
    "violations = norm_df[norm_df['p_value'] < ALPHA]\n",
    "majority_violated = violations.groupby('metric').size() > (norm_df.groupby('metric').size() / 2)\n",
    "# norm_df.to_csv(...)  # only merged section written\n",
    "print(\"Normality by topology (sample):\")\n",
    "print(norm_df.head(12).to_string())\n",
    "print(f\"\\nMajority p < 0.05 (non-normal) per metric: {majority_violated.to_dict()}\")\n",
    "# Short LaTeX paragraph\n",
    "norm_paragraph = (\n",
    "    \"Normality was assessed with Shapiro--Wilk tests per metric and topology. \"\n",
    "    \"The majority of groups showed $p < 0.05$, indicating violation of normality assumptions; \"\n",
    "    \"therefore non-parametric tests (Kruskal--Wallis, Mann--Whitney $U$, Spearman) are used throughout.\"\n",
    ")\n",
    "# Only merged section is written at the end\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Kruskal–Wallis (across four structure groups)\n",
    "\n",
    "If p ≥ 0.05 for a metric, no pairwise testing for that metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T21:50:36.518218Z",
     "iopub.status.busy": "2026-02-20T21:50:36.517323Z",
     "iopub.status.idle": "2026-02-20T21:50:36.590909Z",
     "shell.execute_reply": "2026-02-20T21:50:36.587896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "throughput_rps: H=52.006, p=0.0000 *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_latency_s: H=51.620, p=0.0000 *\n",
      "energy_kj: H=18.129, p=0.0004 *\n",
      "cpu_usage_avg: H=38.656, p=0.0000 *\n",
      "failure_rate: H=96.444, p=0.0000 *\n",
      "p95_latency_s: H=54.321, p=0.0000 *\n"
     ]
    }
   ],
   "source": [
    "kw_results = {}\n",
    "for m in metrics:\n",
    "    if m not in df.columns:\n",
    "        continue\n",
    "    groups = [g[m].dropna().values for _, g in df.groupby('structure_group')]\n",
    "    if any(len(g) < 2 for g in groups):\n",
    "        kw_results[m] = (np.nan, 1.0)\n",
    "        continue\n",
    "    h, p = stats.kruskal(*groups)\n",
    "    kw_results[m] = (h, p)\n",
    "    print(f\"{m}: H={h:.3f}, p={p:.4f} {'*' if p < ALPHA else ''}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Pairwise Mann–Whitney U + Holm correction\n",
    "\n",
    "Contrasts: Dense vs Others, Centralized vs Structured, Seq vs Par, Probabilistic vs Deterministic. Holm correction applied within each metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T21:50:36.597816Z",
     "iopub.status.busy": "2026-02-20T21:50:36.597353Z",
     "iopub.status.idle": "2026-02-20T21:50:36.621849Z",
     "shell.execute_reply": "2026-02-20T21:50:36.619022Z"
    }
   },
   "outputs": [],
   "source": [
    "def dense_vs_others(df, metric):\n",
    "    dense = df[df['structure_group'] == 'dense'][metric].dropna().values\n",
    "    others = df[df['structure_group'].isin(['centralized', 'structured', 'probabilistic'])][metric].dropna().values\n",
    "    if len(dense) < 2 or len(others) < 2:\n",
    "        return np.nan\n",
    "    _, p = stats.mannwhitneyu(dense, others, alternative='two-sided')\n",
    "    return p\n",
    "\n",
    "def centralized_vs_structured(df, metric):\n",
    "    c = df[df['structure_group'] == 'centralized'][metric].dropna().values\n",
    "    s = df[df['structure_group'] == 'structured'][metric].dropna().values\n",
    "    if len(c) < 2 or len(s) < 2:\n",
    "        return np.nan\n",
    "    _, p = stats.mannwhitneyu(c, s, alternative='two-sided')\n",
    "    return p\n",
    "\n",
    "def seq_vs_par(df, metric):\n",
    "    seq = df[df['topology'] == 'sequential_fanout'][metric].dropna().values\n",
    "    par = df[df['topology'] == 'parallel_fanout'][metric].dropna().values\n",
    "    if len(seq) < 2 or len(par) < 2:\n",
    "        return np.nan\n",
    "    _, p = stats.mannwhitneyu(seq, par, alternative='two-sided')\n",
    "    return p\n",
    "\n",
    "def probabilistic_vs_deterministic(df, metric):\n",
    "    prob = df[df['structure_group'] == 'probabilistic'][metric].dropna().values\n",
    "    det = df[df['structure_group'].isin(['centralized', 'structured'])][metric].dropna().values\n",
    "    if len(prob) < 2 or len(det) < 2:\n",
    "        return np.nan\n",
    "    _, p = stats.mannwhitneyu(prob, det, alternative='two-sided')\n",
    "    return p\n",
    "\n",
    "def holm_correction(p_values):\n",
    "    n = len(p_values)\n",
    "    order = np.argsort(p_values)\n",
    "    sorted_p = np.array(p_values)[order]\n",
    "    corrected = np.minimum(sorted_p * (n - np.arange(n)), 1.0)\n",
    "    out = np.empty_like(corrected)\n",
    "    out[order] = corrected\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T21:50:36.629671Z",
     "iopub.status.busy": "2026-02-20T21:50:36.628915Z",
     "iopub.status.idle": "2026-02-20T21:50:36.759224Z",
     "shell.execute_reply": "2026-02-20T21:50:36.756276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise (Holm) computed for metrics where Kruskal–Wallis p < 0.05\n"
     ]
    }
   ],
   "source": [
    "pairwise_holm = {}\n",
    "for m in metrics:\n",
    "    if m not in df.columns:\n",
    "        continue\n",
    "    raw = [\n",
    "        dense_vs_others(df, m),\n",
    "        centralized_vs_structured(df, m),\n",
    "        seq_vs_par(df, m),\n",
    "        probabilistic_vs_deterministic(df, m),\n",
    "    ]\n",
    "    raw_f = [float(x) if not np.isnan(x) else 1.0 for x in raw]\n",
    "    pairwise_holm[m] = holm_correction(raw_f)\n",
    "print(\"Pairwise (Holm) computed for metrics where Kruskal–Wallis p < 0.05\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Build table and write outputs\n",
    "\n",
    "One table: rows = metrics, columns = Dense vs Others | Centralized vs Structured | Seq vs Par | Probabilistic vs Deterministic. Cell = corrected p-value or \"ns\". Bold if p < 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T21:50:36.765520Z",
     "iopub.status.busy": "2026-02-20T21:50:36.764698Z",
     "iopub.status.idle": "2026-02-20T21:50:36.805037Z",
     "shell.execute_reply": "2026-02-20T21:50:36.802144Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Dense vs Others</th>\n",
       "      <th>Centralized vs Structured</th>\n",
       "      <th>Seq vs Par</th>\n",
       "      <th>Probabilistic vs Deterministic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Throughput (RPS)</td>\n",
       "      <td>\\textbf{8.35e-11}</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avg. response time (s)</td>\n",
       "      <td>\\textbf{9.03e-11}</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Energy (kJ)</td>\n",
       "      <td>0.236</td>\n",
       "      <td>\\textbf{0.024}</td>\n",
       "      <td>0.569</td>\n",
       "      <td>\\textbf{0.003}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CPU utilization</td>\n",
       "      <td>\\textbf{1.10e-05}</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.464</td>\n",
       "      <td>\\textbf{5.90e-05}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Failure rate</td>\n",
       "      <td>\\textbf{1.49e-13}</td>\n",
       "      <td>\\textbf{1.34e-09}</td>\n",
       "      <td>\\textbf{0.019}</td>\n",
       "      <td>\\textbf{0.014}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P95 latency (s)</td>\n",
       "      <td>\\textbf{2.59e-12}</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Metric    Dense vs Others Centralized vs Structured  \\\n",
       "0        Throughput (RPS)  \\textbf{8.35e-11}                     0.092   \n",
       "1  Avg. response time (s)  \\textbf{9.03e-11}                     0.126   \n",
       "2             Energy (kJ)              0.236            \\textbf{0.024}   \n",
       "3         CPU utilization  \\textbf{1.10e-05}                     0.360   \n",
       "4            Failure rate  \\textbf{1.49e-13}         \\textbf{1.34e-09}   \n",
       "5         P95 latency (s)  \\textbf{2.59e-12}                     0.323   \n",
       "\n",
       "       Seq vs Par Probabilistic vs Deterministic  \n",
       "0           0.673                          0.121  \n",
       "1           0.853                          0.121  \n",
       "2           0.569                 \\textbf{0.003}  \n",
       "3           0.464              \\textbf{5.90e-05}  \n",
       "4  \\textbf{0.019}                 \\textbf{0.014}  \n",
       "5           0.390                          0.871  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def escape_latex(s):\n",
    "    if not isinstance(s, str):\n",
    "        return s\n",
    "    return s.replace('_', r'\\_').replace('&', r'\\&').replace('%', r'\\%')\n",
    "\n",
    "col_headers = ['Dense vs Others', 'Centralized vs Structured', 'Seq vs Par', 'Probabilistic vs Deterministic']\n",
    "rows_tex = []\n",
    "interpretations = []\n",
    "\n",
    "for metric in metrics:\n",
    "    if metric not in df.columns:\n",
    "        continue\n",
    "    label = METRIC_LABELS.get(metric, metric.replace('_', ' '))\n",
    "    ps = pairwise_holm.get(metric, [1.0] * 4)\n",
    "    cells = []\n",
    "    for j, p in enumerate(ps):\n",
    "        p = ps[j] if j < len(ps) else 1.0\n",
    "        if np.isnan(p):\n",
    "            cells.append('—')\n",
    "        else:\n",
    "            s = f'{p:.3f}' if p >= 0.001 else f'{p:.2e}'\n",
    "            cells.append(f'\\\\textbf{{{s}}}' if p < ALPHA else s)\n",
    "    rows_tex.append([label] + cells)\n",
    "    parts = []\n",
    "    if metric in pairwise_holm:\n",
    "        ps = pairwise_holm[metric]\n",
    "        if not np.isnan(ps[0]) and ps[0] < ALPHA:\n",
    "            parts.append('Dense vs Others significant → dense coordination cost.')\n",
    "        if not np.isnan(ps[1]) and ps[1] < ALPHA:\n",
    "            parts.append('Centralized vs Structured significant → orchestration vs depth.')\n",
    "        if not np.isnan(ps[2]) and ps[2] < ALPHA:\n",
    "            parts.append('Seq vs Par significant → parallelization effect.')\n",
    "        if not np.isnan(ps[3]) and ps[3] < ALPHA:\n",
    "            parts.append('Probabilistic vs Deterministic significant → conditional execution impact.')\n",
    "    if not parts:\n",
    "        parts.append('No significant structural contrast (or Kruskal–Wallis n.s.).')\n",
    "    interpretations.append(f\"{label}: \" + \" \".join(parts))\n",
    "\n",
    "header = ' & '.join(['Metric'] + [escape_latex(c) for c in col_headers]) + ' \\\\\\\\'\n",
    "body = '\\n'.join(' & '.join([escape_latex(str(r[0]))] + list(r[1:])) + ' \\\\\\\\' for r in rows_tex)\n",
    "tab = (\n",
    "    '\\\\begin{table}[htbp]\\n'\n",
    "    '\\\\centering\\n'\n",
    "    '\\\\caption{Structural group contrasts: $p$-values (Holm) for Mann--Whitney $U$ tests. '\n",
    "    'Bold: $p < 0.05$.}\\n'\n",
    "    '\\\\label{tab:structural_groups}\\n'\n",
    "    '\\\\begin{tabular}{lcccc}\\n'\n",
    "    '\\\\toprule\\n' + header + '\\n\\\\midrule\\n' + body + '\\n\\\\bottomrule\\n'\n",
    "    '\\\\end{tabular}\\n\\\\end{table}\\n'\n",
    ")\n",
    "# tab kept in memory for merged section; no individual .tex/.md/.csv written\n",
    "csv_rows = []\n",
    "for metric in metrics:\n",
    "    if metric not in df.columns:\n",
    "        continue\n",
    "    label = METRIC_LABELS.get(metric, metric)\n",
    "    kw_h, kw_p = kw_results.get(metric, (np.nan, np.nan))\n",
    "    row = {'metric': label, 'KW_H': kw_h, 'KW_p': kw_p}\n",
    "    for j, c in enumerate(['Dense_vs_Others', 'Centralized_vs_Structured', 'Seq_vs_Par', 'Prob_vs_Det']):\n",
    "        row[c] = pairwise_holm.get(metric, [np.nan]*4)[j] if metric in pairwise_holm else np.nan\n",
    "    csv_rows.append(row)\n",
    "# pd.DataFrame(csv_rows).to_csv(...)  # only merged section written\n",
    "pass\n",
    "pd.DataFrame(rows_tex, columns=['Metric'] + col_headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 2 — RQ1: Energy differences across topologies\n",
    "\n",
    "**2A.** Kruskal–Wallis on `energy`, `energy_per_request`, `energy_per_success`.  \n",
    "**2B.** Structural contrasts (Mann–Whitney, Holm): Dense vs Others, Centralized vs Structured, Seq vs Par, Prob vs Det.  \n",
    "Output: `energy_tests.tex`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T21:50:36.813024Z",
     "iopub.status.busy": "2026-02-20T21:50:36.812512Z",
     "iopub.status.idle": "2026-02-20T21:50:36.869662Z",
     "shell.execute_reply": "2026-02-20T21:50:36.866021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2A. Kruskal–Wallis (energy metrics):\n",
      "     Metric        H        p\n",
      "Energy (kJ) 19.58097 0.001497\n",
      "\n",
      "2B. Structural contrasts (p-values, bold if p<0.05):\n",
      "     Metric Dense vs Others Centralized vs Structured Seq vs Par    Prob vs Det\n",
      "Energy (kJ)           0.236            \\textbf{0.024}      0.569 \\textbf{0.003}\n"
     ]
    }
   ],
   "source": [
    "ENERGY_METRICS = ['energy_kj']  # Only Energy (kJ) in paper; energy_per_request, energy_per_success excluded from output\n",
    "# 2A Global KW\n",
    "kw_energy = []\n",
    "for m in ENERGY_METRICS:\n",
    "    groups = [g[m].dropna().values for _, g in df.groupby('topology')]\n",
    "    if any(len(g) < 2 for g in groups):\n",
    "        continue\n",
    "    h, p = stats.kruskal(*groups)\n",
    "    kw_energy.append({'Metric': METRIC_LABELS.get(m, m.replace('_', ' ').title()), 'H': h, 'p': p})\n",
    "kw_energy_df = pd.DataFrame(kw_energy)\n",
    "print(\"2A. Kruskal–Wallis (energy metrics):\")\n",
    "print(kw_energy_df.to_string(index=False))\n",
    "\n",
    "# 2B Structural contrasts (reuse pairwise_holm logic for these 3 metrics)\n",
    "def run_four_contrasts(d, met):\n",
    "    raw = [\n",
    "        dense_vs_others(d, met), centralized_vs_structured(d, met),\n",
    "        seq_vs_par(d, met), probabilistic_vs_deterministic(d, met)\n",
    "    ]\n",
    "    raw_f = [float(x) if not np.isnan(x) else 1.0 for x in raw]\n",
    "    return holm_correction(raw_f)\n",
    "\n",
    "energy_contrasts = []\n",
    "for m in ENERGY_METRICS:\n",
    "    h, p = stats.kruskal(*[g[m].dropna().values for _, g in df.groupby('structure_group')])\n",
    "    holm = run_four_contrasts(df, m)\n",
    "    cells = []\n",
    "    for j, pv in enumerate(holm):\n",
    "        s = f'{pv:.3f}' if pv >= 0.001 else f'{pv:.2e}'\n",
    "        cells.append(f'\\\\textbf{{{s}}}' if pv < ALPHA else s)\n",
    "    energy_contrasts.append([METRIC_LABELS.get(m, m.replace('_', ' ').title())] + cells)\n",
    "\n",
    "cols = ['Dense vs Others', 'Centralized vs Structured', 'Seq vs Par', 'Prob vs Det']\n",
    "energy_contrasts_df = pd.DataFrame(energy_contrasts, columns=['Metric'] + cols)\n",
    "print(\"\\n2B. Structural contrasts (p-values, bold if p<0.05):\")\n",
    "print(energy_contrasts_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T21:50:36.876120Z",
     "iopub.status.busy": "2026-02-20T21:50:36.875706Z",
     "iopub.status.idle": "2026-02-20T21:50:36.889866Z",
     "shell.execute_reply": "2026-02-20T21:50:36.887831Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write energy_tests.tex (2A table + 2B table)\n",
    "def esc(s):\n",
    "    return str(s).replace('_', r'\\_').replace('&', r'\\&')\n",
    "kw_lines = ' \\\\\\\\\\n'.join([f\"{esc(r['Metric'])} & {r['H']:.2f} & {r['p']:.3f}\" + (' & \\\\textbf{*}' if r['p'] < ALPHA else '') for _, r in kw_energy_df.iterrows()])\n",
    "ct_lines = ' \\\\\\\\\\n'.join([' & '.join([esc(x) for x in r]) for r in energy_contrasts])\n",
    "energy_tex = (\n",
    "    \"\\\\begin{table}[htbp]\\n\\\\centering\\n\\\\caption{RQ1: Energy across topologies. \"\n",
    "    \"Top: Kruskal--Wallis. Bottom: Structural contrasts (Holm). Bold: $p<0.05$.}\\n\\\\label{tab:energy_tests}\\n\"\n",
    "    \"\\\\small\\n\\\\setlength{\\\\tabcolsep}{4pt}\\n\"\n",
    "    \"\\\\begin{tabular}{lcc}\\n\\\\toprule\\nMetric & H & $p$-value \\\\\\\\\\n\\\\midrule\\n\" + kw_lines + \" \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n\\n\"\n",
    "    \"\\\\begin{tabular}{lcccc}\\n\\\\toprule\\nMetric & Dense vs Others & Cent. vs Struct. & Seq vs Par & Prob vs Det \\\\\\\\\\n\\\\midrule\\n\"\n",
    "    + ct_lines + \" \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n\\\\end{table}\\n\"\n",
    ")\n",
    "# only merged section written\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3 — Size interaction (differences increase with size?)\n",
    "\n",
    "For **energy** and **throughput**: Topology effect, Size effect, Topology × Size interaction. Rank-transform then two-way comparison (Kruskal–Wallis per effect)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T21:50:36.898335Z",
     "iopub.status.busy": "2026-02-20T21:50:36.897844Z",
     "iopub.status.idle": "2026-02-20T21:50:36.987218Z",
     "shell.execute_reply": "2026-02-20T21:50:36.983755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topology, Size, Interaction (p-values):\n",
      "          Metric     Topology         Size  Interaction\n",
      "     Energy (kJ) 1.497375e-03 4.268958e-28 8.940408e-11\n",
      "Throughput (RPS) 3.984533e-10 1.014734e-15 1.007067e-10\n"
     ]
    }
   ],
   "source": [
    "# Size interaction: Topology, Size, and simple interaction via KW per size\n",
    "SIZE_METRICS = ['energy_kj', 'throughput_rps']\n",
    "size_effect_rows = []\n",
    "for m in SIZE_METRICS:\n",
    "    if m not in df.columns:\n",
    "        continue\n",
    "    d = df[[m, 'topology', 'system_size']].dropna()\n",
    "    # Topology effect (KW across topologies, all sizes)\n",
    "    g_topo = [d[d['topology'] == t][m].values for t in d['topology'].unique()]\n",
    "    h_t, p_t = stats.kruskal(*g_topo) if all(len(x) >= 2 for x in g_topo) else (np.nan, 1.0)\n",
    "    # Size effect (KW across sizes, all topologies)\n",
    "    g_size = [d[d['system_size'] == s][m].values for s in d['system_size'].unique()]\n",
    "    h_s, p_s = stats.kruskal(*g_size) if all(len(x) >= 2 for x in g_size) else (np.nan, 1.0)\n",
    "    # Interaction: KW(topology) at each size; report min p (pattern differs across sizes)\n",
    "    p_int_list = []\n",
    "    for sz in sorted(d['system_size'].unique()):\n",
    "        sub = d[d['system_size'] == sz]\n",
    "        g = [sub[sub['topology'] == t][m].values for t in sub['topology'].unique()]\n",
    "        if all(len(x) >= 2 for x in g):\n",
    "            _, p_int = stats.kruskal(*g)\n",
    "            p_int_list.append(p_int)\n",
    "    p_int = min(p_int_list) if p_int_list else np.nan\n",
    "    lab = 'Energy (kJ)' if m == 'energy_kj' else 'Throughput (RPS)'\n",
    "    size_effect_rows.append({'Metric': lab, 'Topology': p_t, 'Size': p_s, 'Interaction': p_int})\n",
    "size_effect_df = pd.DataFrame(size_effect_rows)\n",
    "print(\"Topology, Size, Interaction (p-values):\")\n",
    "print(size_effect_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T21:50:36.991409Z",
     "iopub.status.busy": "2026-02-20T21:50:36.990860Z",
     "iopub.status.idle": "2026-02-20T21:50:37.003396Z",
     "shell.execute_reply": "2026-02-20T21:50:37.000652Z"
    }
   },
   "outputs": [],
   "source": [
    "def esc(s):\n",
    "    return str(s).replace('_', r'\\_').replace('&', r'\\&')\n",
    "def fmt_p(p):\n",
    "    if np.isnan(p):\n",
    "        return '—'\n",
    "    s = f'{p:.3f}' if p >= 0.001 else f'{p:.2e}'\n",
    "    return f'\\\\textbf{{{s}}}' if p < ALPHA else s\n",
    "size_tex_rows = []\n",
    "for _, r in size_effect_df.iterrows():\n",
    "    row = [esc(r['Metric']), fmt_p(r['Topology']), fmt_p(r['Size']), fmt_p(r['Interaction'])]\n",
    "    for i, k in enumerate(['Topology', 'Size', 'Interaction']):\n",
    "        if r[k] < ALPHA and not np.isnan(r[k]):\n",
    "            row[i+1] = f'\\\\textbf{{{row[i+1]}}}'\n",
    "    size_tex_rows.append(' & '.join(row))\n",
    "size_interaction_tex = (\n",
    "    \"\\\\begin{table}[htbp]\\n\\\\centering\\n\\\\caption{Topology $\\\\times$ Size: Kruskal--Wallis $p$-values. \"\n",
    "    \"Interaction = min $p$ (topology effect) across sizes. Bold: $p<0.05$.}\\n\\\\label{tab:size_interaction}\\n\"\n",
    "    \"\\\\small\\n\\\\setlength{\\\\tabcolsep}{4pt}\\n\"\n",
    "    \"\\\\begin{tabular}{lccc}\\n\\\\toprule\\nMetric & Topology & Size & Interaction \\\\\\\\\\n\\\\midrule\\n\"\n",
    "    + ' \\\\\\\\\\n'.join(size_tex_rows) + \" \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n\\\\end{table}\\n\"\n",
    ")\n",
    "# only merged section written\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 4 — RQ2: Performance–energy relationship\n",
    "\n",
    "Per topology: Spearman correlation of throughput_rps, avg_latency_s, failure_rate with energy_kj. Output: `performance_energy_correlation.tex`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T21:50:37.009320Z",
     "iopub.status.busy": "2026-02-20T21:50:37.008600Z",
     "iopub.status.idle": "2026-02-20T21:50:37.071174Z",
     "shell.execute_reply": "2026-02-20T21:50:37.066796Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman (performance vs energy) per topology:\n",
      "            Topology  Throughput_rho  Throughput_p  Latency_rho    Latency_p  Failure_rho    Failure_p\n",
      "  probabilistic_tree       -0.381090  3.773106e-02     0.386429 3.491453e-02     0.340156 6.588236e-02\n",
      "     parallel_fanout       -0.381980  3.724936e-02     0.378865 3.895723e-02     0.426473 1.876713e-02\n",
      "chain_with_branching       -0.839377  6.781687e-09     0.838042 7.548697e-09     0.883871 9.638580e-11\n",
      "        complex_mesh        0.956841  1.462528e-16    -0.959066 7.068084e-17    -0.722358 6.573768e-06\n",
      "   hierarchical_tree       -0.844716  4.374279e-09     0.831368 1.271876e-08     0.797998 1.278193e-07\n",
      "   sequential_fanout       -0.858065  1.355315e-09     0.853170 2.110565e-09    -0.639292 1.429442e-04\n"
     ]
    }
   ],
   "source": [
    "PERF_ENERGY_PAIRS = [\n",
    "    ('throughput_rps', 'Throughput'),\n",
    "    ('avg_latency_s', 'Latency'),\n",
    "    ('failure_rate', 'Failure'),\n",
    "]\n",
    "corr_rows = []\n",
    "for topo in df['topology'].unique():\n",
    "    sub = df[df['topology'] == topo][['energy_kj', 'throughput_rps', 'avg_latency_s', 'failure_rate']].dropna()\n",
    "    if len(sub) < 3:\n",
    "        continue\n",
    "    row = {'Topology': topo}\n",
    "    for col, label in PERF_ENERGY_PAIRS:\n",
    "        r, p = stats.spearmanr(sub['energy_kj'], sub[col])\n",
    "        row[f'{label}_rho'] = r\n",
    "        row[f'{label}_p'] = p\n",
    "    corr_rows.append(row)\n",
    "corr_df = pd.DataFrame(corr_rows)\n",
    "print(\"Spearman (performance vs energy) per topology:\")\n",
    "print(corr_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T21:50:37.078072Z",
     "iopub.status.busy": "2026-02-20T21:50:37.077367Z",
     "iopub.status.idle": "2026-02-20T21:50:37.088358Z",
     "shell.execute_reply": "2026-02-20T21:50:37.086642Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build performance_energy_correlation.tex: Topology | Throughput (rho, p) | Latency (rho, p) | Failure (rho, p)\n",
    "def cell_rho_p(rho, p):\n",
    "    s = f\"{rho:.2f} ({p:.3f})\" if p >= 0.001 else f\"{rho:.2f} ({p:.2e})\"\n",
    "    if p < ALPHA:\n",
    "        s = f\"\\\\textbf{{{s}}}\"\n",
    "    return s\n",
    "corr_tex_rows = []\n",
    "for _, r in corr_df.iterrows():\n",
    "    t = esc(r['Topology'].replace('_', ' ').title())\n",
    "    c1 = cell_rho_p(r['Throughput_rho'], r['Throughput_p'])\n",
    "    c2 = cell_rho_p(r['Latency_rho'], r['Latency_p'])\n",
    "    c3 = cell_rho_p(r['Failure_rho'], r['Failure_p'])\n",
    "    corr_tex_rows.append(f\"{t} & {c1} & {c2} & {c3}\")\n",
    "corr_tex = (\n",
    "    \"\\\\begin{table}[htbp]\\n\\\\centering\\n\\\\caption{RQ2: Spearman correlation (performance vs energy) per topology. \"\n",
    "    \"Bold: $p<0.05$.}\\n\\\\label{tab:performance_energy_correlation}\\n\\\\small\\n\\\\setlength{\\\\tabcolsep}{4pt}\\n\"\n",
    "    \"\\\\begin{tabular}{lccc}\\n\\\\toprule\\nTopology & Throughput--Energy & Latency--Energy & Failure--Energy \\\\\\\\\\n\\\\midrule\\n\"\n",
    "    + ' \\\\\\\\\\n'.join(corr_tex_rows) + \" \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n\\\\end{table}\\n\"\n",
    ")\n",
    "# only merged section written\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 5 — Efficiency: energy_per_rps\n",
    "\n",
    "Kruskal–Wallis + structural contrasts for `energy_per_rps = energy / throughput_rps`. Enables statements like: *Probabilistic tree achieves statistically better energy efficiency than dense mesh.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T21:50:37.096619Z",
     "iopub.status.busy": "2026-02-20T21:50:37.096323Z",
     "iopub.status.idle": "2026-02-20T21:50:37.140569Z",
     "shell.execute_reply": "2026-02-20T21:50:37.138490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy per RPS: H = 39.27 , p = 0.0\n",
      "Structural contrasts: ['Energy per RPS', '\\\\textbf{6.46e-05}', '0.213', '0.530', '\\\\textbf{8.08e-05}']\n"
     ]
    }
   ],
   "source": [
    "# energy_per_rps: KW + structural contrasts\n",
    "m_eff = 'energy_per_rps'\n",
    "g_topo = [df[df['topology'] == t][m_eff].dropna().values for t in df['topology'].unique()]\n",
    "h_eff, p_eff = stats.kruskal(*g_topo) if all(len(x) >= 2 for x in g_topo) else (np.nan, 1.0)\n",
    "kw_eff_row = {'Metric': 'Energy per RPS', 'H': h_eff, 'p': p_eff}\n",
    "# Structural contrasts\n",
    "holm_eff = run_four_contrasts(df, m_eff)\n",
    "cells_eff = [f'{x:.3f}' if x >= 0.001 else f'{x:.2e}' for x in holm_eff]\n",
    "for j, pv in enumerate(holm_eff):\n",
    "    if pv < ALPHA:\n",
    "        cells_eff[j] = f'\\\\textbf{{{cells_eff[j]}}}'\n",
    "eff_contrast_row = ['Energy per RPS'] + cells_eff\n",
    "print(\"Energy per RPS: H =\", round(h_eff, 2), \", p =\", round(p_eff, 4))\n",
    "print(\"Structural contrasts:\", eff_contrast_row)\n",
    "# Append to energy tables and re-save (optional: or save as efficiency.tex)\n",
    "kw_energy_df_plus = pd.concat([kw_energy_df, pd.DataFrame([kw_eff_row])], ignore_index=True)\n",
    "energy_contrasts_plus = energy_contrasts + [eff_contrast_row]\n",
    "eff_tex = (\n",
    "    \"\\\\begin{table}[htbp]\\n\\\\centering\\n\\\\caption{Energy efficiency (energy per RPS): Kruskal--Wallis and structural contrasts. Bold: $p<0.05$.}\\n\"\n",
    "    \"\\\\label{tab:efficiency}\\n\\\\small\\n\\\\setlength{\\\\tabcolsep}{4pt}\\n\"\n",
    "    \"\\\\begin{tabular}{lcc}\\n\\\\toprule\\nMetric & H & $p$-value \\\\\\\\\\n\\\\midrule\\n\"\n",
    "    f\"Energy per RPS & {h_eff:.2f} & {p_eff:.3f}\" + (\" & \\\\textbf{*}\" if p_eff < ALPHA else \"\") + \" \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n\\n\"\n",
    "    \"\\\\begin{tabular}{lcccc}\\n\\\\toprule\\nMetric & Dense vs Others & Cent. vs Struct. & Seq vs Par & Prob vs Det \\\\\\\\\\n\\\\midrule\\n\"\n",
    "    + ' & '.join([esc(x) for x in eff_contrast_row]) + \" \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n\\\\end{table}\\n\"\n",
    ")\n",
    "# only merged section written\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Merged LaTeX section\n",
    "\n",
    "Single section with `\\small` and `\\setlength{\\tabcolsep}{4pt}` for the paper. No effect sizes; p-values only; bold if \\(p < 0.05\\)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T21:50:37.146738Z",
     "iopub.status.busy": "2026-02-20T21:50:37.146473Z",
     "iopub.status.idle": "2026-02-20T21:50:37.157523Z",
     "shell.execute_reply": "2026-02-20T21:50:37.155317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tables/table3_4_5_statistics.tex (include in paper)\n"
     ]
    }
   ],
   "source": [
    "# Merged section: one .tex file to include in the paper\n",
    "merged_content = (\n",
    "    \"% Statistical analysis section for paper. Use \\\\small and compact column spacing.\\n\"\n",
    "    \"\\\\small\\n\\\\setlength{\\\\tabcolsep}{4pt}\\n\\n\"\n",
    "    \"% Normality (documentation)\\n\"\n",
    "    + norm_paragraph + \"\\n\\n\"\n",
    "    \"% RQ1 & structural groups\\n\"\n",
    "    + tab + \"\\n\\n\"\n",
    "    \"% RQ1 Energy\\n\"\n",
    "    + energy_tex + \"\\n\\n\"\n",
    "    \"% Size interaction\\n\"\n",
    "    + size_interaction_tex + \"\\n\\n\"\n",
    "    \"% RQ2 Performance--energy correlation\\n\"\n",
    "    + corr_tex\n",
    ")\n",
    "TABLES_DIR.joinpath('table3_4_5_statistics.tex').write_text(merged_content)\n",
    "print(\"Saved tables/table3_4_5_statistics.tex (include in paper)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T21:50:37.167365Z",
     "iopub.status.busy": "2026-02-20T21:50:37.166432Z",
     "iopub.status.idle": "2026-02-20T21:50:37.180835Z",
     "shell.execute_reply": "2026-02-20T21:50:37.177823Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Interpretation (structural group contrasts)\n",
       "\n",
       "Throughput (RPS): Dense vs Others significant → dense coordination cost.\n",
       "\n",
       "Avg. response time (s): Dense vs Others significant → dense coordination cost.\n",
       "\n",
       "Energy (kJ): Centralized vs Structured significant → orchestration vs depth. Probabilistic vs Deterministic significant → conditional execution impact.\n",
       "\n",
       "CPU utilization: Dense vs Others significant → dense coordination cost. Probabilistic vs Deterministic significant → conditional execution impact.\n",
       "\n",
       "Failure rate: Dense vs Others significant → dense coordination cost. Centralized vs Structured significant → orchestration vs depth. Seq vs Par significant → parallelization effect. Probabilistic vs Deterministic significant → conditional execution impact.\n",
       "\n",
       "P95 latency (s): Dense vs Others significant → dense coordination cost."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show interpretation in notebook\n",
    "from IPython.display import Markdown, display\n",
    "display(Markdown(\"# Interpretation (structural group contrasts)\\n\\n\" + \"\\n\\n\".join(interpretations)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (5_results_analysis venv)",
   "language": "python",
   "name": "venv-5results"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
