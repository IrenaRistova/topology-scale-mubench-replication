{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Boxplots by Topology (aggregated over system size)\n",
        "\n",
        "One figure per metric; each figure has 6 stacked subplots (one per topology).\n",
        "Data are aggregated over `system_size` (5, 10, 20). Style: violin + box, mean diamond, optional reference median line."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "91c8ee4e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "49338d86",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data: /home/irena/Documents/Research Project/topology-scale-mubench-replication/5_results_data/run_table.csv | Exists: True\n"
          ]
        }
      ],
      "source": [
        "cwd = Path('.').resolve()\n",
        "_run_table = Path('5_results_data') / 'run_table.csv'\n",
        "_search = cwd\n",
        "RUN_TABLE_PATH = None\n",
        "for _ in range(6):\n",
        "    candidate = _search / _run_table\n",
        "    if candidate.exists():\n",
        "        RUN_TABLE_PATH = candidate\n",
        "        break\n",
        "    _search = _search.parent\n",
        "if RUN_TABLE_PATH is None:\n",
        "    RUN_TABLE_PATH = cwd / _run_table\n",
        "# Always use 5_results_analysis/figures (even when cwd is .ipynb_checkpoints)\n",
        "if cwd.name == 'notebooks':\n",
        "    _base = cwd.parent\n",
        "elif cwd.name == '.ipynb_checkpoints' and cwd.parent.name == 'notebooks':\n",
        "    _base = cwd.parent.parent\n",
        "else:\n",
        "    _base = cwd\n",
        "FIGURES_DIR = _base / 'figures'\n",
        "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
        "print(\"Data:\", RUN_TABLE_PATH, \"| Exists:\", RUN_TABLE_PATH.exists())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "8469e09c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rows: 180 | Topologies: 6 | Sizes: [5, 10, 20]\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(RUN_TABLE_PATH)\n",
        "df = df[df['__done'] == 'DONE'].copy()\n",
        "\n",
        "TOPOLOGY_ORDER = [\n",
        "    'sequential_fanout', 'parallel_fanout', 'chain_with_branching',\n",
        "    'hierarchical_tree', 'probabilistic_tree', 'complex_mesh',\n",
        "]\n",
        "TOPOLOGY_LABELS = {\n",
        "    'sequential_fanout': 'Seq FO', 'parallel_fanout': 'Par FO',\n",
        "    'chain_with_branching': 'Chain', 'hierarchical_tree': 'Hierarchical',\n",
        "    'probabilistic_tree': 'Probabilistic', 'complex_mesh': 'Mesh',\n",
        "}\n",
        "\n",
        "# Derived columns: latency in s, energy in kJ\n",
        "df['avg_latency_s'] = df['avg_latency_ms'] / 1000\n",
        "df['energy_kj'] = df['energy'] / 1000\n",
        "\n",
        "METRIC_BLOCKS = [\n",
        "    ('throughput_rps', 'Throughput (RPS)'),\n",
        "    ('avg_latency_s', 'Avg Response Time (s)'),\n",
        "    ('energy_kj', 'Energy (kJ)'),\n",
        "    ('cpu_usage_avg', 'CPU utilization (cores)'),\n",
        "    ('failure_rate', 'Failure rate (%)'),\n",
        "]\n",
        "\n",
        "df = df[df['topology'].isin(TOPOLOGY_ORDER)]\n",
        "df['topology'] = pd.Categorical(df['topology'], categories=TOPOLOGY_ORDER, ordered=True)\n",
        "\n",
        "_scale_pct = ('cpu_usage_avg' in df.columns and df['cpu_usage_avg'].max() <= 1.5) or ('failure_rate' in df.columns and df['failure_rate'].max() <= 1.5)\n",
        "if _scale_pct:\n",
        "    df = df.copy()\n",
        "    if 'cpu_usage_avg' in df.columns and df['cpu_usage_avg'].max() <= 1.5:\n",
        "        df['cpu_usage_avg'] = df['cpu_usage_avg'] * 100\n",
        "    if 'failure_rate' in df.columns and df['failure_rate'].max() <= 1.5:\n",
        "        df['failure_rate'] = df['failure_rate'] * 100\n",
        "\n",
        "print(\"Rows:\", len(df), \"| Topologies:\", df['topology'].nunique(), \"| Sizes:\", sorted(df['system_size'].unique().tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "4e09b1fd",
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_outliers(series):\n",
        "    \"\"\"IQR-based outlier removal (like reference).\"\"\"\n",
        "    if series is None or len(series) == 0:\n",
        "        return series\n",
        "    Q1 = series.quantile(0.25)\n",
        "    Q3 = series.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower = Q1 - 1.5 * IQR\n",
        "    upper = Q3 + 1.5 * IQR\n",
        "    return series[(series >= lower) & (series <= upper)]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (5_results_analysis venv)",
      "language": "python",
      "name": "venv-5results"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
